# 6 随机变量的独立性

什么叫独立? 在通常的理解中, 独立就是不依赖. 那么什么叫随机变量的独立? 简言之, 就是随机变量的取值不受制于其它随机变量取值的影响, 在概率的意义下. 

这是一个在客观世界里常见的现象. 小到掷骰子的游戏, 大到悬浮在液体中的微粒所受到的液体分子运动在不同的时间区间内带来的冲击力. 另一方面, 独立性会给数学上的处理带来极大的方便, 是我们考虑概率问题时必须用好用尽的一个性质.

我们曾经对离散型随机变量定义了独立性. 现在把这个概念拓广到一般情况并对它进行系统的研究.



[TOC]

## 6.1 基本定义及性质

### 6.1.1 独立的定义

我们从最简单的情况, 即两个随机变量的情况开始.

> 设$\xi, \eta$是随机变量*.* 若
> $$
> P(\xi \leqslant a, \eta \leqslant b) = P(\xi \leqslant a)P(\eta \leqslant b)
> $$
> 则称$\xi, \eta$独立.

用分布函数表示, 独立性就是
$$
F_{\xi, \eta}(x,y) = F_{\xi}(x)F_{\eta}(y)
$$
容易验证, 此条件等价于:
$$
\forall x_1 < x_2, y_1<y_2, F(x_2,y_2)-F(x_1,y_2)-F(x_2,y_1)+F(x_1,y_1)=(F_{\xi}(x_2)-F_{\xi}(x_1))(F_{\eta}(y_2)-F_{\eta}(y_1))
$$
对于离散型随机变量, $\xi, \eta \text{独立} \Leftrightarrow p_{i,j}^{(\xi,\eta)} = p_i^{(\xi)}p_j^{(\eta)}$

对于连续型随机变量, $\xi, \eta \text{独立} \Leftrightarrow p_{\xi, \eta}(x,y) = p_{\xi}(x)p_{\eta}(y)$, 其中$(x,y)$是$p$的连续点.



### 6.1.2 独立的一些性质

现在考虑下面的问题: 如果$\xi, \eta$是随机变量, $f \in \mathscr{B}^2$ . 问: 在求期望$\mathbb{E}[f(\xi,\eta)]$时, 能否先固定一个, 即先求$\phi(x) = \mathbb{E}_{\eta}[f(x, \eta)]$, 得到$x$的函数, 再将$\xi$代入到这个函数中去, 然后求这个随机变量函数的期望$\mathbb{E}_{\xi}[\phi(\xi)]$?

回答一般是否定的. 例如, 取$f(x,y)=xy$. 此时, 对任意两个随机变量$\xi, \eta$, 上面公式成立意味着$\mathbb{E}[\xi\eta]=\mathbb{E}[\xi]\mathbb{E}[\eta]$, 即$\xi, \eta$不相关.这显然一般是不对的.

但在独立的情况, 这样做是可以的, 即我们有下面的定理:

> 设$f : \mathbb{R} \to \mathbb{R}$为非负Borel可测, $(\xi, \eta)$为二维随机变量*.* 令
> $$
> \phi(x) := \mathbb{E}[f(x, \eta)]
> $$
> 则$\phi: \mathbb{R} \to \mathbb{R}$为非负Borel可测, 且$\xi, \eta$为独立的充要条件对任意这样的$f$
> $$
> \mathbb{E}[f(\xi, \eta)] = \mathbb{E}[\phi(\xi)]
> $$

分别考虑正负部, 我们有

> 将上定理中的条件$f$非负换为$f(\xi, \eta)$可积, 结论依然成立.

我们还有:

> 设$\xi, \eta$是独立随机变量, $\zeta = \xi + \eta$. 则
> $$
> F_{\zeta}(z) = \int_{-\infty}^{\infty}F_{\eta}(z-x)dF_{\xi}(x)
> $$

我们还有一个推论:

> 设$\xi, \eta$独立*,* 且皆可积*,* 则$\xi, \eta$亦可积*,* 且
> $$
> \mathbb{E}[\xi\eta] = \mathbb{E}[\xi]\mathbb{E}[\eta]
> $$

证明*.* 取$f(x, y) = |xy|$, 我们有$\mathbb{E}[|\xi\eta|] = \mathbb{E}[|\xi|]\mathbb{E}[|\eta|] < \infty$, 因此$\xi\eta$可积. 

再取$f(x,y) = xy$就得到所要的等式.



考虑随机变量生成的$\sigma$-代数.

设$\xi$为随机变量, 称
$$
\sigma(\xi) := \xi^{-1}(\mathscr{B}) = \{\xi^{-1}(B), B \in \mathscr{B}\}
$$
为**ξ生成的σ-代数**. 即*σ*(*ξ*)为使*ξ*可测的最小*σ*-代数. 

> 设$\xi, \eta$，那么$\sigma(\xi)$与$\sigma(\eta)$独立, 即
> $$
> P(\xi \in A, \eta \in B) = P(\xi \in A)P(\eta \in B), \forall A, B \in \mathscr{B}
> $$

证明*.* 记$\mathscr{A}=\{(-\infty,x], x\in\mathbb{R}\}$, 则$\mathscr{B} = \sigma(\mathscr{A})$. 因为$\xi, \eta$独立, 所以集类
$$
\xi^{-1}(\mathscr{A}) = \{\{\xi \leqslant x\}, x\in\mathbb{R}\}
$$


*ξ* *−*1 (*A* ) = *{{**ξ* ⩽ *x**}**, x* *∈* R*}* 与*η* *−*1 (*A* ) = *{{**η* ⩽ *x**}**, x* *∈* R*}*

独立, 且它们都是*π*-类. 由命题4.1.1有

*σ*(*ξ*) = *ξ* *−*1 (*B*) = *ξ* *−*1 (*σ*(*A* )) = *σ*(*ξ* *−*1 (*A* ))*.*

同理*σ*(*η*) = *σ*(*η* *−*1 (*A* )). 所以由命题3.4.3, *σ*(*ξ*)与*σ*(*η*)独立.



由此我们还可以得到：

> 设$\xi, \eta$独立, 则对任意Borel函数$f, g$, $f(\xi)$与$g(\eta)$独立.



## 6.2 不相关与独立的关系

我们曾经证明, 当$\xi, \eta$独立时, 只要$\mathbb{E}[\xi]$与$\mathbb{E}[\eta]$均存在, 那么就有$\mathbb{E}[\xi\eta]=\mathbb{E}[\xi]\mathbb{E}[\eta]$, 而这就是不相关. 所以在期望存在时, 独立意味着不相关 (但要注意独立性对任意随机变量, 而不只是对期望存在的随机变量, 均可定义; 而不相关性则只有对期望存在的随机变量才能定义).

自然的问题是, 不相关是否意味着独立? 即使简单地从定义来看, 这个问题的答案也是否定的, 因为不相关是个整体的概念(求期望是整体概念), 但独立是局部概念(需要严格对于任意局部).



顺着这个思路, 可以很容易找出反例.



但在一个重要的特殊情形, 不相关和独立是等价的, 这就是$(\xi, \eta)$服从二维正态分布的情况.

设$(\xi, \eta)$服从二维正态分布, 即$(\xi, \eta) \sim \mathcal{N}(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho)$, 其密度函数为
$$
p(x,y) = \frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp\{-\frac{1}{2(1-\rho^2)}\left[\frac{(x-\mu_1)^2}{\sigma_1^2}+\frac{(y-\mu_2)^2}{\sigma_2^2}-\frac{2\rho(x-\mu_1)(y-\mu_2)}{\sigma_1\sigma_2}\right]\}
$$
我们曾经证明
$$
\xi \sim \mathcal{N}(\mu_1, \sigma_1), \eta\sim\mathcal{N}(\mu_2,\sigma_2)
$$
而它们的协方差为
$$
\text{Cov}(\xi,\eta) = \sigma_1\sigma_2\rho
$$
所以$\rho$就是相关系数. $\xi, \eta$不相关时$\rho=0$, 于是
$$
p(x,y) = \frac{1}{2\pi\sigma_1\sigma_2}\exp\{-\frac{(x-\mu_1)^2}{2\sigma_1^2}-\frac{(y-\mu_2)^2}{2\sigma_2^2}\}=p_{\xi}(x)p_{\eta}(y)
$$


从而*ξ*与*η*独立. 所以, 我们有

> 如果$(\xi, \eta)$服从二维正态分布，$\xi, \eta$不相关 $\Leftrightarrow$ $\xi, \eta$独立. 

注意这里的前提条件：(*ξ, η*)服从二维正态分布. 注意即使(*ξ, η*)不服从二维正态分布, *ξ*,*η*的边沿分布仍然有可能是正态分布, 此时定理不再成立.

从另一个角度看, 也可以这样说：两个独立的正态分布的联合分布是二维正态分布, 两个不相关的正态分布的联合分布未必是二维正态分布

这又一次说明了, 不同的联合分布可以对应同样的边沿分布.



## 6.3 独立随机变量之和

本节我们研究独立随机变量之和的收敛性. 具体地说, 假设$\{\xi_i\}$是独立随机变量序列. 我们要研究
$$
S_n = \sum_{i=1}^n\xi_i
$$
的收敛性问题.

有别于一般的随机级数, 这个由独立随机变量组成的级数有许多独特的性质, 其中第一个就是:

> $S_n$几乎必然收敛和依概率收敛是等价的*.*



那么什么样的$\{\xi_i\}$能使得$S_n$收敛呢？为得到$S_n$依概率收敛的条件, 我们需要下面的不等式.

> **(Chatterji不等式)** 设$1 \leqslant p < 2$, 则
> $$
> ||S_n||_p^p \leqslant 2^{2-p}\sum_{i=1}^n||\xi_i||_p^p
> $$

> **(Rio不等式)** 设$p \geqslant 2$, 则
> $$
> ||S_n||_p^2 \leqslant (p-1)\sum_{i=1}^n||\xi_i||_p^2
> $$



因此

> 设$p \geqslant 1$, 若
> $$
> \sum_{i=1}^n||\xi_i||_p^{\min\{p,2\}}<\infty
> $$
> 则$S_n$几乎必然收敛，也即依概率收敛.
